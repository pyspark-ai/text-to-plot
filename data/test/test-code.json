[
    {
        "uuid": "52fcf5d3c22208abaa31b8cc30022a06",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate df to get average mpg for each model year\ndf_agg = df.groupBy('model-year').agg({'mpg': 'avg'}).orderBy('model-year')\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Rename columns for better readability\ndf_pandas.columns = ['Model Year', 'Average MPG']\n\n# Create line plot using plotly\nfig = px.line(df_pandas, x='Model Year', y='Average MPG', title='Progression of Average MPG Across Model Years')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "ec73adc6934ff4f4cff10edd5e5c1b17",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_agg = df.groupBy('cylinders').agg({'horsepower': 'mean'}).withColumnRenamed(\"avg(horsepower)\", \"avg_horsepower\")\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create bar chart using plotly\nfig = px.bar(df_pandas, x='cylinders', y='avg_horsepower', title='Average Horsepower Across Unique Cylinder Configurations')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "34e87e52e74581a8990985e605e37ad9",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter df for model year 80\ndf = df.filter(df['model-year'] == 80)\n\n# Convert Spark DataFrame to Pandas DataFrame\npandas_df = df.select('weight', 'mpg').toPandas()\n\n# Create scatter plot\nfig = px.scatter(pandas_df, x='weight', y='mpg', title=\"Relationship between a vehicle's weight and its miles per gallon for the model year 80\")\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "ddf74488a1fce4a6dfdafde276eda711",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('horsepower').count().orderBy('count', ascending=False).limit(5)\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie chart\nfig = px.pie(df_pandas, values='count', names='horsepower', title='Proportion of Vehicles Based on Their Horsepower')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "8e9da47ee132852084c40ac9765d3bcd",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter df for model year 70\ndf_70 = df.filter(df['model-year'] == 70)\n\n# Convert to pandas DataFrame\ndf_70_pd = df_70.toPandas()\n\n# Create boxplot\nfig = px.box(df_70_pd, y='acceleration')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "2a246a32815bf6054eec04f118940efa",
        "code": "import pandas as pd\nimport plotly.express as px\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('model-year').count().orderBy('model-year')\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create the area plot\nfig = px.area(df_pandas, x='model-year', y='count', title='Count of Cars Across Model Years')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "a3df096615fd32644b3648b6aaba1888",
        "code": "import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Aggregation: Count of cars per model year\ndf_agg = df.groupBy('model-year').agg(F.count('*').alias('count'))\n\n# Convert to pandas DataFrame\ndf_pd = df_agg.orderBy('model-year').toPandas()\n\n# Calculate cumulative count\ndf_pd['cumulative_count'] = df_pd['count'].cumsum()\n\n# Plot\nfig = px.area(df_pd, x='model-year', y='cumulative_count', title='Cumulative count of cars across model years')\nprint(fig.to_json())"
    },
    {
        "uuid": "18cd554f41627b50b95dd07b62b7fbbd",
        "code": "import pandas as pd\nimport plotly.express as px\nfrom pyspark.sql import SparkSession\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the Spark DataFrame\n# Convert Spark DataFrame to Pandas DataFrame\npandas_df = df.toPandas()\n\n# Create boxplot of horsepower distribution\nfig = px.box(pandas_df, y='horsepower')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "21203369b9aaaa1a7bb99a96ee139ba8",
        "code": "import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Aggregation\ndf_agg = df.groupBy('cylinders').count()\n\n# Convert to pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create pie plot\nfig = px.pie(df_pandas, values='count', names='cylinders', title='Proportion of Vehicles Based on Their Cylinders')\nprint(fig.to_json())"
    },
    {
        "uuid": "e3e611c3b77094e91c258c3e722d884b",
        "code": "import pandas as pd\nimport plotly.express as px\nfrom pyspark.sql import SparkSession\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter df for vehicles with 25 miles per gallon\ndf_filtered = df.filter(df.mpg == 25)\n\n# Convert Spark DataFrame to Pandas DataFrame\npandas_df = df_filtered.select('cylinders', 'acceleration').toPandas()\n\n# Create hexagonal bin plot\nfig = px.density_heatmap(pandas_df, x='cylinders', y='acceleration', nbinsx=20, nbinsy=20)\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "69cd29f7676e8f43281d20c55e558453",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('cylinders').count()\n\n# Convert to pandas DataFrame\npdf = df_agg.toPandas()\n\n# Calculate proportion\npdf['proportion'] = pdf['count'] / pdf['count'].sum()\n\n# Plot\nfig = px.pie(pdf, values='proportion', names='cylinders', title='Proportion of vehicles by cylinder configurations')\nprint(fig.to_json())"
    },
    {
        "uuid": "0c8cb74c8ddbd3c1eda2208f9bb88fc1",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('model-year').agg({'weight': 'avg'})\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Rename the columns for better readability\ndf_pandas.columns = ['Model Year', 'Average Weight']\n\n# Sort the data by Model Year\ndf_pandas = df_pandas.sort_values('Model Year')\n\n# Create a line plot\nfig = px.line(df_pandas, x='Model Year', y='Average Weight', title='Trend of Average Vehicle Weight Over Model Years')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "95de169b1baceeaa1162a026276ff3dc",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame with the required columns\n\n# Filter the DataFrame for the 80 model year\ndf_80 = df.filter(df['model-year'] == 80)\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_80.select('mpg', 'acceleration').toPandas()\n\n# Create a scatter plot using Plotly\nfig = px.scatter(df_pandas, x='mpg', y='acceleration', title='Relationship between MPG and Acceleration for 80 Model Year')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "10f3262cf38b852376d89c3b60b5937d",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('continent').count()\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie chart\nfig = px.pie(df_pandas, values='count', names='continent', title='Number of countries breakdown by continent')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d38386edacc0f2071ced78d9ef74099b",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame with the required columns\n# Filter for African nations and sort by GDP\ndf_africa = df.filter(df['continent'] == 'Africa').sort('gdpPercap')\n\n# Take only the first 10 rows (10 nations with lowest GDP)\ndf_africa = df_africa.limit(10)\n\n# Convert to pandas DataFrame for plotting\ndf_africa_pd = df_africa.toPandas()\n\n# Create scatter plot with Plotly\nfig = px.scatter(df_africa_pd, x='pop', y='gdpPercap', color='country', title='Population vs GDP in 10 African Nations with Lowest GDP')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "7c1f9d4e8eea35ad7119b1e74fe1e432",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Filter for European countries and sort by GDP in descending order\ndf_europe = df.filter(df.continent == 'Europe').sort(df.gdpPercap.desc())\n\n# Take top 10 countries\ndf_top10 = df_europe.limit(10)\n\n# Convert to pandas DataFrame for plotting\ndf_pandas = df_top10.toPandas()\n\n# Create scatter plot\nfig = px.scatter(df_pandas, x='pop', y='lifeExp', color='country',\n                 size='gdpPercap', hover_data=['gdpPercap'],\n                 labels={'pop':'Population', 'lifeExp':'Life Expectancy'},\n                 title='Life Expectancy vs Population for 10 European Countries with Highest GDP')\nprint(fig.to_json())"
    },
    {
        "uuid": "a197ad507eeb76f61ec72dd08dd7f4b4",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the required columns\n\n# Filter for Asian countries and sort by GDP in descending order\ndf_asia = df.filter(df['continent'] == 'Asia').sort(df['gdpPercap'], ascending=False)\n\n# Take top 5 countries\ndf_top5 = df_asia.limit(5)\n\n# Convert to pandas DataFrame\npdf = df_top5.toPandas()\n\n# Create scatter plot\nfig = px.scatter(pdf, x='pop', y='lifeExp', color='country', title='Life Expectancy vs Population for 5 Asian Countries with Highest GDP')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "b64d57c3940f467db7c050ee8df651d9",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame for African countries\ndf_africa = df.filter(df.continent == 'Africa')\n\n# Aggregate the DataFrame\ndf_agg = df_africa.groupBy('country').agg({'pop': 'sum'})\n\n# Convert the Spark DataFrame to a Pandas DataFrame\npd_df = df_agg.toPandas()\n\n# Create a box plot of population distribution for African countries\nfig = px.box(pd_df, y='sum(pop)', labels={'sum(pop)': 'Population'}, title='Population Distribution for African Countries')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "f691b585aabaed6f5b1256e6d2c3adb2",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame for the countries of interest\ndf_filtered = df.filter(df.country.isin(['China', 'India', 'Japan']))\n\n# Aggregate the DataFrame\ndf_agg = df_filtered.groupBy('country').agg({'lifeExp': 'mean'})\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a bar plot\nfig = px.bar(df_pandas, x='country', y='avg(lifeExp)', title='Average Life Expectancy in China, India, and Japan')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "648abc259f9d642dea61c3e5accba19e",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the required columns\n# Filter for Asia and aggregate population by country\ndf_asia = df.filter(df.continent == 'Asia').groupBy('country').sum('pop')\n\n# Convert to pandas DataFrame\ndf_pandas = df_asia.toPandas()\n\n# Rename columns for better readability in plot\ndf_pandas.columns = ['Country', 'Population']\n\n# Create pie plot\nfig = px.pie(df_pandas, values='Population', names='Country', title='Proportion of Population by Country in Asia')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "2d75e4e08f5d120c1774003e83fe73ef",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame for the countries of interest\ndf_filtered = df.filter(df.country.isin(['United States', 'Brazil', 'Mexico']))\n\n# Aggregate the data\ndf_agg = df_filtered.groupBy('country').agg({'pop': 'sum'})\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create the bar plot\nfig = px.bar(df_pandas, x='country', y='sum(pop)', title='Population of United States, Brazil and Mexico')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "7af25dfe4a8cced137336357adf62fbc",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the specified columns\n\n# Filter for Asia and aggregate\ndf_asia = df.filter(df.continent == 'Asia').groupBy('country').agg({'pop': 'sum'})\n\n# Convert to pandas DataFrame\ndf_asia_pd = df_asia.toPandas()\n\n# Rename columns for better readability\ndf_asia_pd.columns = ['Country', 'Population']\n\n# Create box plot\nfig = px.box(df_asia_pd, y=\"Population\", title=\"Population Distribution for Countries in Asia\")\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "e27ae1591d9b680fef733f5c792b27d4",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the specified columns\n\n# Filter for Asian countries and sort by GDP\ndf_asia = df.filter(df['continent'] == 'Asia').sort(df['gdpPercap'].desc())\n\n# Take top 5 countries\ndf_top5 = df_asia.limit(5)\n\n# Convert to pandas DataFrame\ndf_pandas = df_top5.toPandas()\n\n# Create histogram\nfig = px.histogram(df_pandas, x='country', y='pop', nbins=5, title='Population of 5 Asian Countries with Highest GDP')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "f9344e7169fa2ab7934ea057b2d4a4cf",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame with the given columns\n\n# Filter for European countries\ndf_europe = df.filter(df.continent == 'Europe')\n\n# Get the top 4 countries by GDP per capita\ndf_top4 = df_europe.sort(df.gdpPercap.desc()).limit(4)\n\n# Convert to pandas DataFrame\ndf_pandas = df_top4.toPandas()\n\n# Create pie chart\nfig = px.pie(df_pandas, values='pop', names='country', title='Population Breakdown for 4 European Countries with Highest GDP')\nprint(fig.to_json())"
    },
    {
        "uuid": "aa8596d0908727281f7ae7acdbcdfffd",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter Asian countries and select 'country' and 'lifeExp' columns\ndf_asia = df.filter(df['continent'] == 'Asia').select('country', 'lifeExp')\n\n# Convert Spark DataFrame to Pandas DataFrame\npdf_asia = df_asia.toPandas()\n\n# Create a box plot of life expectancy distribution for Asian countries\nfig = px.box(pdf_asia, y='lifeExp', labels={'lifeExp':'Life Expectancy'}, title='Life Expectancy Distribution for Asian Countries')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "10b262adf02fadf8943ee74d78aed733",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.filter(df.continent == 'Europe').groupBy('country').agg({'pop': 'sum'}).orderBy('sum(pop)', ascending=False).limit(5)\n\n# Convert to pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Rename the columns for better visualization\ndf_pandas.columns = ['Country', 'Population']\n\n# Create the bar plot\nfig = px.bar(df_pandas, x='Country', y='Population', title='Population of Top 5 European Nations')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "f15f25520b76179b859e72e04b6bb94e",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is your DataFrame\n# Aggregate to get the total population for each country\ndf_agg = df.groupBy('country').sum('pop')\n\n# Order by population in descending order and limit to 5\ndf_top5 = df_agg.orderBy(df_agg['sum(pop)'].desc()).limit(5)\n\n# Convert to pandas DataFrame\ndf_pd = df_top5.toPandas()\n\n# Rename the columns for better visualization\ndf_pd.columns = ['Country', 'Population']\n\n# Create bar plot\nfig = px.bar(df_pd, x='Country', y='Population', title='Population comparison for the 5 most populous countries')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "beebd4e77842206db87034cae7d3074a",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('continent').sum('pop')\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Rename the columns for better readability\ndf_pandas.columns = ['Continent', 'Population']\n\n# Create a pie chart\nfig = px.pie(df_pandas, values='Population', names='Continent', title='Population breakdown by continent')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "e9fadf2db6491f9f663a151b11a34abd",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is your DataFrame\n# Aggregate data\ndf_agg = df.groupBy(\"country\").agg({\"gdpPercap\": \"sum\"}).orderBy(\"sum(gdpPercap)\", ascending=False).limit(8)\n\n# Convert to pandas DataFrame\ndf_pd = df_agg.toPandas()\n\n# Rename columns for better visualization\ndf_pd.columns = ['Country', 'Total GDP']\n\n# Create bar plot\nfig = px.bar(df_pd, x='Country', y='Total GDP', title='Top 8 Countries by GDP')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "8992063e1128109a5747800723a68c1e",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate to find average life expectancy per continent\ndf_agg = df.groupBy('continent').agg({'lifeExp': 'avg'})\n\n# Convert to pandas DataFrame\ndf_pd = df_agg.toPandas()\n\n# Rename columns for better readability in plot\ndf_pd.columns = ['Continent', 'Average Life Expectancy']\n\n# Sort DataFrame by 'Average Life Expectancy'\ndf_pd = df_pd.sort_values('Average Life Expectancy')\n\n# Create line plot\nfig = px.line(df_pd, x='Continent', y='Average Life Expectancy', title='Trend of Average Life Expectancy Across Continents')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "a0e8593c8be15334f65562d335b12d14",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the specified columns\n\n# Filter for Americas countries\ndf_americas = df.filter(df['continent'] == 'Americas')\n\n# Get 5 countries with the lowest GDP\ndf_lowest_gdp = df_americas.orderBy('gdpPercap').limit(5)\n\n# Convert to pandas DataFrame for plotting\ndf_pandas = df_lowest_gdp.toPandas()\n\n# Create plot\nfig = px.bar(df_pandas, x='country', y='gdpPercap', color='lifeExp', \n             labels={'gdpPercap':'GDP per Capita', 'lifeExp':'Life Expectancy'},\n             title='Relationship between GDP and Life Expectancy in 5 Americas Countries with the Lowest GDP')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "9384e18dc2100b4e1372d13f2380ff21",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is your DataFrame\n# Filter for European countries\ndf_europe = df.filter(df.continent == 'Europe')\n\n# Aggregate data\ndf_agg = df_europe.groupBy('country').agg({'pop': 'sum', 'gdpPercap': 'avg'})\n\n# Convert to pandas DataFrame\npdf = df_agg.toPandas()\n\n# Rename columns\npdf.columns = ['country', 'total_pop', 'avg_gdp']\n\n# Create hexbin plot\nfig = px.density_heatmap(pdf, x='total_pop', y='avg_gdp', nbinsx=20, nbinsy=20, color_continuous_scale='Viridis')\n\n# Show plot\nprint(fig.to_json())"
    },
    {
        "uuid": "9d9033683d033462b41aa2170bbf1dbf",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Aggregation: Count the number of volcanoes per country\ndf_agg = df.groupBy('Country').count().orderBy('count', ascending=False)\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Select the top 5 countries with the most volcanoes\ndf_top5 = df_pandas.head(5)\n\n# Create a bar plot\nfig = px.bar(df_top5, x='Country', y='count', title='Top 5 Countries with the Most Volcanoes')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d4134bb91a4b8bb73378abc4a018a5fd",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the specified columns\n\n# Filter for volcanoes in Japan and sort by elevation in descending order\ndf_japan = df.filter(df['Country'] == 'Japan').sort(df['Elev'].desc())\n\n# Take the top 8 highest volcanoes\ndf_top8 = df_japan.limit(8)\n\n# Convert to pandas DataFrame for plotting\ndf_pandas = df_top8.toPandas()\n\n# Create line plot\nfig = px.line(df_pandas, x='Volcano Name', y='Elev', title='Elevation Trend of the 8 Highest Volcanoes in Japan')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "dc75a9216f65bf1642e27181ddf79f06",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter df for volcanoes in China\ndf_china = df.filter(df['Country'] == 'China')\n\n# Aggregate df to get the count of volcanoes at each elevation\ndf_agg = df_china.groupBy('Elev').count()\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a histogram of the distribution of volcano elevations\nfig = px.histogram(df_pandas, x='Elev', nbins=50, title='Distribution of Volcano Elevations in China')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "f7ed0b0b21f2e3f870b94e46090312b0",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame to only include volcanoes in the United States\ndf_usa = df.filter(df['Country'] == 'United States')\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_usa_pd = df_usa.select('Elev').toPandas()\n\n# Create a boxplot of the elevation distribution of volcanoes in the United States\nfig = px.box(df_usa_pd, y='Elev', title='Elevation Distribution of Volcanoes in the United States')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d1dd56ec1aac7e419c34db69401bca19",
        "code": "import pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter for volcanoes in Russia and sort by elevation\ndf_russia = df.filter(F.col('Country') == 'Russia').sort(F.col('Elev'), ascending=False)\n\n# Select the 8 highest volcanoes\ndf_top8 = df_russia.limit(8)\n\n# Convert to pandas DataFrame\ndf_pd = df_top8.toPandas()\n\n# Create area plot\nfig = px.area(df_pd, x='Volcano Name', y='Elev', title='Elevation progression of the 8 highest volcanoes in Russia')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "b1e7a0df0e30a0a2cd487b8ad96cbb6b",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame for volcanoes in Peru\ndf_peru = df.filter(df['Country'] == 'Peru')\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_peru_pd = df_peru.toPandas()\n\n# Create a scatter plot of latitude versus longitude\nfig = px.scatter(df_peru_pd, x='Longitude', y='Latitude', \n                 title='Scatter plot of latitude versus longitude for volcanoes in Peru')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "0a631ab7a5a2e0b7b511fa39270c0f51",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter data for Mexico\ndf_mexico = df.filter(df['Country'] == 'Mexico')\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_mexico_pd = df_mexico.toPandas()\n\n# Create Mapbox density map\nfig = px.density_mapbox(df_mexico_pd, lat='Latitude', lon='Longitude', z='Elev', radius=10,\n                        center=dict(lat=23.6345, lon=-102.5528), zoom=5,\n                        mapbox_style=\"stamen-terrain\")\n\nprint(fig.to_json())"
    },
    {
        "uuid": "5a43048f0d2064558debc4933bbc521d",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Filter for volcanoes in China\ndf_china = df.filter(df['Country'] == 'China')\n\n# Aggregate by volcano type\ndf_agg = df_china.groupBy('Type').count()\n\n# Convert to pandas DataFrame\npdf = df_agg.toPandas()\n\n# Create pie plot\nfig = px.pie(pdf, values='count', names='Type', title='Distribution of Volcano Types in China')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "ecb89636cd86865c9b57bab5dd670440",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the specified columns\n\n# Aggregate the data\ndf_agg = df.groupBy('Status').count()\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie plot of the distribution of volcano status\nfig = px.pie(df_pandas, values='count', names='Status', title='Distribution of Volcano Status')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "18b11a17d6a1aec8965c0a78a81c83a3",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame for volcanoes in France\ndf_france = df.filter(df['Country'] == 'France')\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_france.toPandas()\n\n# Create a scatter plot of latitude versus longitude\nfig = px.scatter(df_pandas, x='Longitude', y='Latitude', \n                 title='Scatter plot of latitude versus longitude for volcanoes in France')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d7f745254e7841f6da6d5bd9bed0093b",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame for Turkey\ndf_turkey = df.filter(df['Country'] == 'Turkey')\n\n# Aggregate the DataFrame by volcano type\ndf_agg = df_turkey.groupBy('Type').count()\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie plot of volcano types breakdown in Turkey\nfig = px.pie(df_pandas, values='count', names='Type', title='Volcano Types Breakdown in Turkey')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "6c6e8d9bea0cc9361370897035d39202",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame to only include volcanoes in China\ndf_china = df.filter(df['Country'] == 'China')\n\n# Aggregate the DataFrame by volcano status\ndf_agg = df_china.groupBy('Status').count()\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie plot of the distribution of volcano status in China\nfig = px.pie(df_pandas, values='count', names='Status', title='Distribution of Volcano Status in China')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "84cafe5df2beab045a5a0805b9696e8c",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# No aggregation is needed for a boxplot\n\n# Convert Spark DataFrame to Pandas DataFrame\npandas_df = df.toPandas()\n\n# Create boxplot\nfig = px.box(pandas_df, y=\"Elev\")\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "41815648aad919ee5e44373245a46480",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame to only include volcanoes in China\ndf_china = df.filter(df['Country'] == 'China')\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_china.toPandas()\n\n# Create a scatter plot of latitude versus longitude\nfig = px.scatter(df_pandas, x='Longitude', y='Latitude', \n                 color='Volcano Name', \n                 title='Scatter plot of latitude versus longitude for volcanoes in China')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "67715b39560ad737e9479754f9f57737",
        "code": "import pandas as pd\nimport plotly.express as px\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame to only include volcanoes in China\ndf_china = df.filter(col('Country') == 'China')\n\n# Sort the DataFrame by elevation and select the 5 lowest volcanoes\ndf_lowest = df_china.sort('Elev').limit(5)\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_lowest.toPandas()\n\n# Create a density map using plotly\nfig = px.density_mapbox(df_pandas, lat='Latitude', lon='Longitude', z='Elev', radius=10,\n                        center=dict(lat=35, lon=105), zoom=3,\n                        mapbox_style=\"stamen-terrain\", title='5 Lowest Volcanoes in China')\n\nprint(fig.to_json())"
    },
    {
        "uuid": "402b5a1b1aa1d3592eccbd58e68bec74",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame with the given columns\n\n# Filter for volcanoes in the United States and sort by elevation\ndf_us = df.filter(df['Country'] == 'United States').sort('Elev')\n\n# Select the 5 lowest volcanoes\ndf_lowest = df_us.limit(5)\n\n# Convert to pandas DataFrame\ndf_pd = df_lowest.toPandas()\n\n# Create Mapbox density map\nfig = px.density_mapbox(df_pd, lat='Latitude', lon='Longitude', z='Elev', radius=10,\n                        center=dict(lat=40, lon=-100), zoom=3,\n                        mapbox_style=\"stamen-terrain\")\n\nprint(fig.to_json())"
    },
    {
        "uuid": "208b9e8526928ad817eeae0b9ab060a0",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Filter for volcanoes in the United States\ndf_us = df.filter(df['Country'] == 'United States')\n\n# Aggregate to get count of each volcano type\ndf_agg = df_us.groupBy('Type').count()\n\n# Convert to pandas DataFrame\npdf = df_agg.toPandas()\n\n# Create pie chart\nfig = px.pie(pdf, values='count', names='Type', title='Breakdown of Volcano Types in the United States')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "9eb1889d22d91b67db0a00a5a5adc502",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is your DataFrame\n# Filter the DataFrame for volcanoes in Mexico\ndf_mexico = df.filter(df['Country'] == 'Mexico')\n\n# Aggregate the data\ndf_agg = df_mexico.groupBy('Elev').count()\n\n# Convert the DataFrame to pandas\npandas_df = df_agg.toPandas()\n\n# Plot the data\nfig = px.histogram(pandas_df, x='Elev', y='count', nbins=50, \n                   labels={'Elev':'Elevation (m)', 'count':'Number of Volcanoes'},\n                   title='Distribution of Volcano Elevations in Mexico')\nprint(fig.to_json())"
    },
    {
        "uuid": "ccff80f7966bfba8b9f3e7f38a8cf05e",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame with the given columns\n\n# Sort the DataFrame by latitude in ascending order and take the first 5 rows\ndf_south = df.sort('Latitude').limit(5)\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_south.toPandas()\n\n# Create a scatter plot using Plotly\nfig = px.scatter(df_pandas, x='Latitude', y='Elev', color='Volcano Name', title='Relationship between Latitude and Elevation for the 5 Southernmost Volcanoes')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "42d090ca01f86f45a77bbfdfdc6ba56a",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a DataFrame with the specified columns\n\n# Aggregate the data\ndf_agg = df.groupBy('Country').count().orderBy('count', ascending=False).limit(5)\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Rename the columns for better readability\ndf_pandas.columns = ['Country', 'Number of Volcanoes']\n\n# Create a bar plot using plotly\nfig = px.bar(df_pandas, x='Country', y='Number of Volcanoes', title='Comparison of the number of volcanoes in the top 5 countries')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "389e4875f5a7851b30abbd9c78203584",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Filter for volcanoes in Mexico and sort by elevation in descending order\ndf_mexico = df.filter(df['Country'] == 'Mexico').sort(df['Elev'].desc())\n\n# Select the top 5 highest volcanoes\ndf_top5 = df_mexico.limit(5)\n\n# Convert to pandas DataFrame\ndf_pandas = df_top5.toPandas()\n\n# Create line plot\nfig = px.line(df_pandas, x='Volcano Name', y='Elev', title='Trend of Volcano Elevations in the 5 Highest Volcanoes in Mexico')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "865010d949ec55e10ed3f72793271609",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter df for volcanoes with elevations above 4000\ndf_filtered = df.filter(df['Elev'] > 4000)\n\n# Convert to pandas DataFrame\ndf_pandas = df_filtered.toPandas()\n\n# Create a histogram of volcano elevations\nfig = px.histogram(df_pandas, x='Elev', nbins=30, labels={'Elev':'Elevation (m)'}, \n                   title='Distribution of Volcano Elevations Above 4000m')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "b20df99eaed1a254565541c739cdfc2a",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('pyspark_plot').getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_agg = df.groupBy('Pclass').count()\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create bar plot using plotly\nfig = px.bar(df_pandas, x='Pclass', y='count', labels={'Pclass':'Passenger Class', 'count':'Number of Passengers'}, title='Number of Passengers in Each Class')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "0c2938bdf3aeaad805de147ab0d28422",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport plotly.express as px\nimport pandas as pd\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already defined and loaded with data\n# Aggregate data\ndf_agg = df.groupBy(\"Age\").count()\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create histogram using plotly\nfig = px.histogram(df_pandas, x=\"Age\", y=\"count\", nbins=30, title=\"Age distribution of passengers\")\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "541e1c9630256d86663b9575ec8577f6",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('Titanic').getOrCreate()\n\n# Assuming df is already defined and loaded with data\n# Perform aggregation to get the count of each gender\ngender_df = df.groupBy('Sex').count()\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ngender_pd_df = gender_df.toPandas()\n\n# Create a pie chart using plotly\nfig = px.pie(gender_pd_df, values='count', names='Sex', title='Gender Distribution Aboard the Titanic')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d801fb18092e3871e5bb13fc99c9d63f",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport plotly.express as px\nimport pandas as pd\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already a Spark DataFrame\n# Perform aggregation\ndf_agg = df.groupBy('Survived').count()\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create bar plot using plotly\nfig = px.bar(df_pandas, x='Survived', y='count', labels={'Survived':'Survival Status', 'count':'Number of Passengers'}, title='Number of Survivors and Non-Survivors')\nprint(fig.to_json())"
    },
    {
        "uuid": "ddd22e2820fc2be79e68a03daf53f5a9",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('plotly_visualization').getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_agg = df.groupBy('Pclass').agg({'Fare': 'mean'}).orderBy('Pclass')\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Rename columns for better readability\ndf_pandas.columns = ['Passenger Class', 'Average Fare']\n\n# Create area plot\nfig = px.area(df_pandas, x='Passenger Class', y='Average Fare', title='Fare Distribution Over Different Passenger Classes')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "546c0ade2ca7760710cf80225e2adfca",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame to only include rows where age is between 35 and 40\ndf_filtered = df.filter((df['Age'] >= 35) & (df['Age'] <= 40))\n\n# Aggregate the DataFrame by 'Age' and 'Fare', calculating the mean fare for each age\ndf_agg = df_filtered.groupBy('Age').mean('Fare')\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a scatter plot of age against fare\nfig = px.scatter(df_pandas, x='Age', y='avg(Fare)', title='Scatter plot of Age against Fare')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "58d14c4cdc071c0fd2e63548a63b2c8f",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already defined and loaded with data\n# Perform aggregation on df\ndf_grouped = df.groupBy('Embarked').count()\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_grouped.toPandas()\n\n# Create a bar plot using plotly\nfig = px.bar(df_pandas, x='Embarked', y='count', title='Number of Passengers Boarding from Each Embarkation Port')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "75f28ca202f7d93704794c1f8b751c25",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already defined and loaded with data\n# Aggregate df to get the count of fares\ndf_agg = df.groupBy('Fare').count()\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a histogram using plotly\nfig = px.histogram(df_pandas, x='Fare', y='count', nbins=50, labels={'Fare':'Fare', 'count':'Count'})\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "1bea5b4e9813527a893ac13c365487c7",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('lifeboat_distribution').getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_grouped = df.groupBy('Survived').count()\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_grouped.toPandas()\n\n# Rename columns for better understanding\ndf_pandas.columns = ['Survived', 'Count']\n\n# Replace 'Survived' column values for better understanding\ndf_pandas['Survived'] = df_pandas['Survived'].replace({0: 'Not in lifeboat', 1: 'In lifeboat'})\n\n# Create pie chart using Plotly\nfig = px.pie(df_pandas, values='Count', names='Survived', title='Distribution of Passengers in Lifeboats')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "e9289de414dc300a8ce482595ab3a503",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('pyspark_plot').getOrCreate()\n\n# Perform aggregation on df\ndf_agg = df.groupBy('SibSp').count()\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create bar plot using plotly\nfig = px.bar(df_pandas, x='SibSp', y='count', labels={'SibSp':'Number of Siblings/Spouses', 'count':'Number of Passengers'}, title='Number of Siblings/Spouses Each Passenger Had Aboard')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "7d2ce282c025f10b43947f4c47abe365",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport plotly.express as px\nimport pandas as pd\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already defined and loaded with data\n# Aggregate data\ndf_agg = df.groupBy('Sex').agg({'Fare': 'collect_list'}).alias('Fares')\n\n# Convert to pandas DataFrame\ndf_pd = df_agg.toPandas()\n\n# Prepare data for plot\ndata = pd.concat([pd.DataFrame({'Sex': row.Sex, 'Fare': row['collect_list(Fare)']}) for _, row in df_pd.iterrows()])\n\n# Create boxplot\nfig = px.box(data, x='Sex', y='Fare', points=\"all\", title='Fare Distribution for Male and Female Passengers')\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d3937c25fd1e9754d4470b1a4e37b77f",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.graph_objects as go\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already a Spark DataFrame\n# Aggregate data\ndf_agg = df.groupBy('Survived', 'Age').count().orderBy('Age')\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pd = df_agg.toPandas()\n\n# Split data into survivors and non-survivors\nsurvivors = df_pd[df_pd['Survived'] == 1]\nnon_survivors = df_pd[df_pd['Survived'] == 0]\n\n# Create area plot\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=survivors['Age'], y=survivors['count'],\n    fill='tozeroy',\n    mode='none',\n    name='Survivors'\n))\n\nfig.add_trace(go.Scatter(\n    x=non_survivors['Age'], y=non_survivors['count'],\n    fill='tonexty',\n    mode='none',\n    name='Non-Survivors'\n))\n\nprint(fig.to_json())"
    },
    {
        "uuid": "970e3a6d13dae80b46f35f3f26e1486f",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Filter the DataFrame to only include rows where age is between 0 and 10\ndf_filtered = df.filter((df.Age >= 0) & (df.Age <= 10))\n\n# Aggregate the DataFrame by age and calculate the average fare for each age\ndf_aggregated = df_filtered.groupBy('Age').avg('Fare')\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_aggregated.toPandas()\n\n# Create a scatter plot of age against average fare\nfig = px.scatter(df_pandas, x='Age', y='avg(Fare)', title='Scatter plot of Age (0-10) against Average Fare')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d9088e91a9eff3c2edc812a72c866ede",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Aggregation: Count the number of females in each class\ndf_agg = df.filter(df.Sex == 'female').groupBy('Pclass').count()\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie plot using plotly\nfig = px.pie(df_pandas, values='count', names='Pclass', title='Number of Females in Each Class')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "3adde3cbc94e43206c4f06eb43a31456",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Assuming df is already defined and loaded with data\n# Perform aggregation to get the count of passengers based on their embarkation port\ndf_agg = df.groupBy('Embarked').count()\n\n# Convert the Spark DataFrame to a Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie chart using plotly\nfig = px.pie(df_pandas, values='count', names='Embarked', title='Distribution of passengers based on their embarkation port')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "d09fa23d31efdf31329ff331806da15d",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_agg = df.groupBy('Sex').agg({'Survived': 'mean'})\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pd = df_agg.toPandas()\n\n# Rename columns for better readability\ndf_pd.columns = ['Sex', 'Survival Rate']\n\n# Create bar plot using plotly\nfig = px.bar(df_pd, x='Sex', y='Survival Rate', title='Survival Rate by Gender')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "6664f0f208e6bd2e55c52181e322e85f",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a Spark DataFrame\n# Aggregate data\ndf_agg = df.filter(df['Survived'] == 1).select('Age')\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create boxplot\nfig = px.box(df_pandas, y=\"Age\")\n\n# Display plot\nprint(fig.to_json())"
    },
    {
        "uuid": "97217dfee3e96a76a71b4cf6cc10d04f",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('plotly_visualization').getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_agg = df.groupBy('Embarked').agg({'Fare': 'sum'}).withColumnRenamed(\"sum(Fare)\", \"TotalFare\")\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create area plot using plotly\nfig = px.area(df_pandas, x='Embarked', y='TotalFare', title='Fare Distribution Over Different Embarkation Ports')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "1c56ef705aede7b0ba64521780792ba7",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('pyspark_plot').getOrCreate()\n\n# Assuming df is already a Spark DataFrame\n# Perform aggregation\ndf_agg = df.groupBy('Age').agg({'SibSp': 'sum'}).withColumnRenamed('sum(SibSp)', 'Total_SibSp')\n\n# Convert Spark DataFrame to Pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create scatter plot using plotly\nfig = px.scatter(df_pandas, x='Age', y='Total_SibSp', title='Scatter plot of age against the number of siblings/spouses')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "ac56f416752889cc3ceab6bb761ad31f",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('pyspark_plot').getOrCreate()\n\n# Assuming df is already defined\n# Perform aggregation\ndf_agg = df.groupBy('Parch').count()\n\n# Convert Spark DataFrame to Pandas DataFrame\npandas_df = df_agg.toPandas()\n\n# Create bar plot using plotly\nfig = px.bar(pandas_df, x='Parch', y='count', labels={'Parch':'Number of Parents/Children', 'count':'Number of Passengers'}, title='Number of Parents/Children Each Passenger Had Aboard')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "41a1f6b3aa3dbbfe83aeba68a7df43ea",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is already a Spark DataFrame\n# Perform aggregation to get the age distribution for non-survivors\ndf_non_survivors = df.filter(df['Survived'] == 0)\n\n# Convert Spark DataFrame to Pandas DataFrame\npdf_non_survivors = df_non_survivors.toPandas()\n\n# Create boxplot using plotly\nfig = px.box(pdf_non_survivors, y='Age', title='Age Distribution for Non-Survivors')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "a218fdbb97d1e1d12dee83f815ed3f2c",
        "code": "# Import necessary libraries\nfrom pyspark.sql import SparkSession\nimport plotly.express as px\nimport pandas as pd\n\n# Start Spark session\nspark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n\n# Perform aggregation on Spark DataFrame\ndf_grouped = df.groupBy('Pclass', 'Survived').count()\n\n# Convert Spark DataFrame to Pandas DataFrame\npandas_df = df_grouped.toPandas()\n\n# Create a new DataFrame with survival rate for each passenger class\nsurvival_rate_df = pd.concat([pandas_df[pandas_df['Survived'] == 1].set_index('Pclass'), \n                              pandas_df[pandas_df['Survived'] == 0].set_index('Pclass')], \n                             axis=1, keys=['Survived', 'Not Survived'])\n\n# Calculate survival rate\nsurvival_rate_df['Survival Rate'] = survival_rate_df['Survived']['count'] / (survival_rate_df['Survived']['count'] + survival_rate_df['Not Survived']['count'])\n\n# Reset index\nsurvival_rate_df.reset_index(inplace=True)\n\n# Plot pie chart\nfig = px.pie(survival_rate_df, values='Survival Rate', names='Pclass', title='Survival Rate for Each Passenger Class')\nprint(fig.to_json())"
    },
    {
        "uuid": "3b57bdf4cf7e0414a714d4a6d3f6437d",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.appName('lifeboat').getOrCreate()\n\n# Aggregate data\ndf_agg = df.groupBy('Cabin').count()\n\n# Convert to pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create bar plot\nfig = px.bar(df_pandas, x='Cabin', y='count', title='Number of Passengers in Each Lifeboat')\nprint(fig.to_json())"
    },
    {
        "uuid": "187ada0c20a0449eedee6fbe1a1c5a27",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n\n# Aggregate data\ndf_survived = df.filter(df['Survived'] == 1).select('Age').na.drop()\ndf_not_survived = df.filter(df['Survived'] == 0).select('Age').na.drop()\n\n# Convert to pandas DataFrame\npd_df_survived = df_survived.toPandas()\npd_df_not_survived = df_not_survived.toPandas()\n\n# Concatenate DataFrames\npd_df = pd.concat([pd_df_survived.assign(Survived='Yes'), pd_df_not_survived.assign(Survived='No')])\n\n# Plot\nfig = px.histogram(pd_df, x=\"Age\", color=\"Survived\", nbins=30, title=\"Distribution of Age for Survivors and Non-Survivors\")\nprint(fig.to_json())"
    },
    {
        "uuid": "4ebf16febfae5fcf4d0d51b8883b5ee8",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# First, we need to create age groups. Let's assume each group spans 10 years.\ndf = df.withColumn('AgeGroup', (df['Age'] / 10).cast('integer'))\n\n# Now, we aggregate to find the average fare for each age group\ndf_agg = df.groupBy('AgeGroup').avg('Fare')\n\n# Convert the aggregated Spark DataFrame to a pandas DataFrame\npdf = df_agg.toPandas()\n\n# Sort the DataFrame by age group for a meaningful plot\npdf = pdf.sort_values('AgeGroup')\n\n# Create the line plot\nfig = px.line(pdf, x='AgeGroup', y='avg(Fare)', labels={'AgeGroup':'Age Group', 'avg(Fare)':'Average Fare'}, title='Trend of Average Fare over Age Groups')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "0687dcd9898b79c12363c87a1efea59b",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupby('Embarked').sum('Survived')\n\n# Convert to pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create the plot\nfig = px.bar(df_pandas, x='Embarked', y='sum(Survived)', title='Number of survivors from each embarkation port')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "1d5102a6958b13542ba6914572cfd05e",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate the data\ndf_agg = df.groupBy('Pclass').agg({'Fare': 'mean'}).orderBy('Pclass')\n\n# Convert the DataFrame to pandas DataFrame\npdf = df_agg.toPandas()\n\n# Rename the columns for better readability\npdf.columns = ['Ticket Class', 'Average Fare']\n\n# Create a boxplot\nfig = px.box(pdf, x='Ticket Class', y='Average Fare', title='Fare Variability Across Ticket Classes')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "1e096e8f7ea22580325c9c1afa0b8a89",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is your DataFrame\n# First, we need to create age groups. Let's assume each group spans 10 years.\ndf = df.withColumn(\"AgeGroup\", (df[\"Age\"] / 10).cast(\"integer\") * 10)\n\n# Now, let's count the number of passengers in each age group\ndf_grouped = df.groupBy(\"AgeGroup\").count().orderBy(\"AgeGroup\")\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_grouped.toPandas()\n\n# Calculate the cumulative sum of passengers\ndf_pandas['CumulativeCount'] = df_pandas['count'].cumsum()\n\n# Create the area plot\nfig = px.area(df_pandas, x='AgeGroup', y='CumulativeCount', title='Cumulative number of passengers across age groups')\n\n# Display the plot\nprint(fig.to_json())"
    },
    {
        "uuid": "59521074144a12e252a1f58d8511b8c1",
        "code": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\n\n# Start Spark session\nspark = SparkSession.builder.getOrCreate()\n\n# Assuming df is the DataFrame\n# Aggregate df to get the count of passengers by ticket class\ndf_agg = df.groupBy('Pclass').count()\n\n# Convert the Spark DataFrame to a pandas DataFrame\ndf_pandas = df_agg.toPandas()\n\n# Create a pie chart\nfig = px.pie(df_pandas, values='count', names='Pclass', title='Proportion of passengers by ticket class')\n\n# Display the plot\nprint(fig.to_json())"
    }
]